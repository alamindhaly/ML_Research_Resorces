# -*- coding: utf-8 -*-
"""Copy of BC_final_code

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yZ3o12bTknzZRSGinjT6aSRgiSfJaQje
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import warnings
warnings.filterwarnings('ignore')

from google.colab import files
files.upload()

df_file = pd.read_csv("/content/data.csv")

"""#preprocessing """

df_file

df_file.info()

df_file.drop(['Unnamed: 32'], axis ='columns', inplace = True)

df_file.shape

df_file.isna().values.any()

dummy = pd.get_dummies(df_file['diagnosis'])

df_file2 = pd.concat((df_file,dummy),axis=1)

df_file2

df_file2=df_file2.drop(['diagnosis'],axis='columns')

df_file2

dff=df_file2.drop(['M'],axis=1)

dff

df=dff.rename(columns={'B':'diagnosis'})

df.head(10)

"""#visualization """

df.columns

mean_col = ['diagnosis','radius_mean', 'texture_mean', 'perimeter_mean',
       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',
       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']

sns.pairplot(df[mean_col],hue = 'diagnosis', palette='Accent')

##Correlation values between features
df.corr()

plt.figure(figsize=(20,12))
sns.heatmap(df.corr(),cmap='coolwarm', annot = True, linewidths=.1)
plt.show()

#check the balance in deendent feature
plt.figure(figsize=(10, 8))
sns.scatterplot(y = df.index , x= df.diagnosis,palette = 'BrBe')

#CHECKING DISTRIBUTION OF DATA IN FEATURES
fig, axes = plt.subplots(2,3,figsize=(20,8))
sns.distplot(df['area_mean'],ax = axes[0,0])
sns.distplot(df['radius_mean'],ax = axes[0,1])
sns.distplot(df['texture_mean'],ax = axes[0,2])
sns.distplot(df['perimeter_mean'],ax = axes[1,0])
sns.distplot(df['smoothness_mean'],ax = axes[1,1])
sns.distplot(df['concavity_mean'],ax = axes[1,2])

#CONVERTING THE CATEGORICAL DATA TO NUMERICAL
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

df['diagnosis'] = le.fit_transform(df['diagnosis'])

df['diagnosis']

x = df.drop(['diagnosis'],axis='columns')

x

y = df['diagnosis']

y

"""#Split"""

from sklearn.model_selection import train_test_split

train_X,test_X,train_y,test_y =train_test_split(x,y,random_state=42 ,test_size=0.2)
print('test_X',test_X.shape)
print('training_X',train_X.shape)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
train_X = sc.fit_transform(train_X)
test_X = sc.fit_transform(test_X)

"""#fit model"""

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import AdaBoostClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import BaggingClassifier, VotingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_digits
digits = load_digits()

pip install vaex

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# def models(train_X, train_y):
# 
# 
#   ##Support Vector Classifier 1
#   svm_model = SVC(C=10,kernel='poly',gamma=100)
#   svm_model.fit(train_X, train_y) 
# 
#   ##Random Forest Classification 2
#   rf_model = RandomForestClassifier(n_estimators = 5, criterion='entropy', random_state = 20)
#   rf_model.fit(train_X, train_y)
# 
#   ##Logistic Classification 3
#   lr_model = LogisticRegression(random_state= 42)
#   lr_model.fit(train_X, train_y)
# 
#   ##GradientBoosting Classifier 5
#   gb_model=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
#   gb_model.fit(train_X, train_y)
# 
#   ## AdaBoost Classifier 6
#   ada_model = AdaBoostClassifier(n_estimators = 20, random_state = 42)
#   ada_model.fit(train_X, train_y)
# 
# 
#   ##XGBclassifier  7
#   xgb_model =XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
#   xgb_model.fit(train_X, train_y)
# 
# 
# 
# 
#   print("Trainning Accuracty of Support Vector Classifier : ",svm_model.score(train_X, train_y))
#   print("Trainning Accuracty of RandomForestClassifier Model : ",rf_model.score(train_X, train_y))
#   print("Trainning Accuracty of Logistic Classification Model : ",lr_model.score(train_X, train_y))
#   print("Trainning Accuracty of Gradient Boosting Classifier Model : ",gb_model.score(train_X, train_y))
#   print("Trainning Accuracty of  AdaBoosting Classifier Model : ",ada_model.score(train_X, train_y))
#   print("Trainning Accuracty of XGB classifier Model : ",xgb_model.score(train_X, train_y))
# 
# 
# 
# 
#   return svm_model, rf_model, lr_model, gb_model, ada_model, xgb_model

model = models(train_X, train_y)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# from sklearn.metrics import confusion_matrix, classification_report, log_loss, cohen_kappa_score
# from sklearn import metrics
# 
# for i in range(len(model)):
#   print('Confusion matrix of model',i , 'is :')
#   cm = confusion_matrix(test_y, model[i].predict(test_X))
#   TP = cm[0][0]
#   TN = cm[1][1]
#   FP = cm[0][1]
#   FN = cm[1][0]
#   print(cm)
#   print()
#   result1 = classification_report(test_y, model[i].predict(test_X))
#   print("Classification Report : ", )
#   print (result1)
#   print()
#   var = ((TP + TN)/(TP + TN + FP + FN)) * 100 
#   print('Testing accuracy : ',var)
#   print('Sensitivity : ',TP/(TP+FN))
#   print('Specificity : ',TN/(TN+FP))
#   print('False positive rate : ',FP/(FP+TN))
#   print('False negative rate : ',FN/(FN+TP))
#   print('Negative predictive value : ',TN/(TN+FN))
#   print('False Discovery rate: ',FP/(TP+FP))
#   print('Mean Absolute Error: ',metrics.mean_absolute_error(test_y,model[i].predict(test_X)))
#   print('Mean Squared Error: ',metrics.mean_squared_error(test_y,model[i].predict(test_X)))
#   print('Root Mean Squared Error: ',np.sqrt(metrics.mean_squared_error(test_y,model[i].predict(test_X))))
#   print('Log Loss: ',metrics.log_loss(test_y,model[i].predict(test_X)))
#   print('Cohen_Kappa_Score: ',cohen_kappa_score(test_y,model[i].predict(test_X)))
#   
# 
#   print()
#   print()
#   name = ['Support Vector Machine Model','Random Forest Model','Logistic Classification','GradientBoosting Classifier','AdaBoost Classifier','XGBclassifier']
#   col_value = ['blue','purple','orange','green','black','yellow']
#   model_accuracy = pd.Series(data=[var], index=[name[i]])
#   fig = plt.figure(figsize=(5,5))
#   width = 0.75
#   model_accuracy.sort_values().plot.bar(alpha=0.8, color=[col_value[i]])
#   plt.xticks(rotation=0)
#   plt.title('Model Accuracy')
#   plt.ylabel('Accuracy (%)')
#   plt.show()
#   print()
#   print()



"""##AUC & ROC Curve"""



# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# from sklearn.metrics import roc_curve, roc_auc_score
# import sklearn.metrics as metrics
# 
# ##support Vector Machine Roc curve
# svm_model = SVC(probability=True)
# svm_model.fit(train_X, train_y) 
# y_score1 = svm_model.predict_proba(test_X)[:,1]
# ##Plot Receiving Operating Characteristic Curve
# ##Create true and false positive rate
# false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
# print('score of support vector machine: ',roc_auc_score(test_y, y_score1))
# #plot Roc curves
# plt.subplots(1, figsize=(5,5))
# plt.title('Support Vector Machine Roc Curve')
# plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Support Vector Machine")
# plt.plot([0,1], ls="--")
# plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.legend()
# plt.show()
# print()
# print() 
# ##Support Vector  Machine Aus curve
# svm = SVC(probability=True)
# svm.fit(train_X,train_y)
# y_pred_proba=svm.predict(test_X)
# ##Auc Curve
# plt.subplots(1, figsize=(5,5))
# y_pred_proba=svm.predict_proba(test_X)[::,1]
# fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
# auc=metrics.roc_auc_score(test_y,y_pred_proba)
# plt.title('Support Vector  Machine Aus curve')
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
# plt.legend(loc=4)
# plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# from sklearn.metrics import roc_curve, roc_auc_score
# import sklearn.metrics as metrics
# 
# ##Random Forest Classification
# from sklearn.ensemble import RandomForestClassifier
# rf_model = RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 20)
# rf_model.fit(train_X, train_y)
# y_score1 = rf_model.predict_proba(test_X)[:,1]
# ##Plot Receiving Operating Characteristic Curve
# ##Create true and false positive rate
# false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
# print('score of Random Forest Classification: ',roc_auc_score(test_y, y_score1))
# #plot Roc curves
# plt.subplots(1, figsize=(5,5))
# plt.title('Random Forest Classification Roc Curve')
# plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Random Forest Classification")
# plt.plot([0,1], ls="--")
# plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.legend()
# plt.show()
# print()
# print()
# ##Random Forest Classification Aus curve
# rf_model = RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 20)
# rf_model.fit(train_X, train_y)
# y_pred_proba=rf_model.predict(test_X)
# ##Auc Curve
# plt.subplots(1, figsize=(5,5))
# y_pred_proba=rf_model.predict_proba(test_X)[::,1]
# fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
# auc=metrics.roc_auc_score(test_y,y_pred_proba)
# plt.title('Random Forest Classification Aus curve')
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
# plt.legend(loc=4)
# plt.show()
#

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# from sklearn.metrics import roc_curve, roc_auc_score
# import sklearn.metrics as metrics
# 
# ##Logistic Regression Classification
# lr_model = LogisticRegression(random_state= 42)
# lr_model.fit(train_X, train_y)
# y_score1 = lr_model.predict_proba(test_X)[:,1]
# ##Plot Receiving Operating Characteristic Curve
# ##Create true and false positive rate
# false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
# print('score of Logistic Regression : ',roc_auc_score(test_y, y_score1))
# #plot Roc curves
# plt.subplots(1, figsize=(5,5))
# plt.title('Logistic Regression Roc Curve')
# plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Logistic Regression")
# plt.plot([0,1], ls="--")
# plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.legend()
# plt.show()
# print()
# print()
# ##Logistic Regression Aus curve
# lr_model = LogisticRegression(random_state= 42)
# lr_model.fit(train_X, train_y)
# y_pred_proba=lr_model.predict(test_X)
# ##Auc Curve
# plt.subplots(1, figsize=(5,5))
# y_pred_proba=rf_model.predict_proba(test_X)[::,1]
# fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
# auc=metrics.roc_auc_score(test_y,y_pred_proba)
# plt.title('Logistic Regression Aus curve')
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
# plt.legend(loc=4)
# plt.show()
#

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# from sklearn.metrics import roc_curve, roc_auc_score
# import sklearn.metrics as metrics
# 
# 
# ##GradientBoostingClassifier 5
# gb_model=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
# gb_model.fit(train_X, train_y)
# y_score1 = gb_model.predict_proba(test_X)[:,1]
# ##Plot Receiving Operating Characteristic Curve
# ##Create true and false positive rate
# false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
# print('Gradient Boosting Classifier: ',roc_auc_score(test_y, y_score1))
# #plot Roc curves
# plt.subplots(1, figsize=(5,5))
# plt.title('Gradient Boosting Classifier')
# plt.plot(false_positive_rate1,true_positive_rate1 ,label= "GradientBoosting Classifier")
# plt.plot([0,1], ls="--")
# plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.legend()
# plt.show()
# print()
# print()
# ##GradientBoostingClassifier 5
# gb_model=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
# gb_model.fit(train_X, train_y)
# y_pred_proba=gb_model.predict(test_X)
# ##Auc Curve
# plt.subplots(1, figsize=(5,5))
# y_pred_proba=gb_model.predict_proba(test_X)[::,1]
# fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
# auc=metrics.roc_auc_score(test_y,y_pred_proba)
# plt.title('GradientBoosting Classifier')
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
# plt.legend(loc=4)
# plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# from sklearn.metrics import roc_curve, roc_auc_score
# import sklearn.metrics as metrics
# 
# 
# ##Adaboost classifier      7
# ada_model = AdaBoostClassifier(n_estimators = 20, random_state = 42)
# ada_model.fit(train_X, train_y)
# y_score1 = ada_model.predict_proba(test_X)[:,1]
# ##Plot Receiving Operating Characteristic Curve
# ##Create true and false positive rate
# false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
# print('Adabost Classifier: ',roc_auc_score(test_y, y_score1))
# #plot Roc curves
# plt.subplots(1, figsize=(5,5))
# plt.title('Adabost Classifier')
# plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Adabost Classifier")
# plt.plot([0,1], ls="--")
# plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.legend()
# plt.show()
# print()
# print()
# ##Adabost classifier      7
# ada_model = AdaBoostClassifier(n_estimators = 20, random_state = 42)
# ada_model.fit(train_X, train_y)
# y_pred_proba=ada_model.predict(test_X)
# ##Auc Curve
# plt.subplots(1, figsize=(5,5))
# y_pred_proba=ada_model.predict_proba(test_X)[::,1]
# fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
# auc=metrics.roc_auc_score(test_y,y_pred_proba)
# plt.title('Adabost Classifier')
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
# plt.legend(loc=4)
# plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# from sklearn.metrics import roc_curve, roc_auc_score
# import sklearn.metrics as metrics
# 
# 
# ##XGB classifier      7
# xgb_model =XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 200)
# xgb_model.fit(train_X, train_y)
# y_score1 = xgb_model.predict_proba(test_X)[:,1]
# ##Plot Receiving Operating Characteristic Curve
# ##Create true and false positive rate
# false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
# print('XGB Classifier: ',roc_auc_score(test_y, y_score1))
# #plot Roc curves
# plt.subplots(1, figsize=(5,5))
# plt.title('XGB Classifier')
# plt.plot(false_positive_rate1,true_positive_rate1 ,label= "XGB Classifier")
# plt.plot([0,1], ls="--")
# plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.legend()
# plt.show()
# print()
# print()
# ##XGB classifier      7
# xgb_model =XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
# xgb_model.fit(train_X, train_y)
# y_pred_proba=xgb_model.predict(test_X)
# ##Auc Curve
# plt.subplots(1, figsize=(5,5))
# y_pred_proba=xgb_model.predict_proba(test_X)[::,1]
# fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
# auc=metrics.roc_auc_score(test_y,y_pred_proba)
# plt.title('XGB Classifier')
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
# plt.legend(loc=4)
# plt.show()

"""## KFold Cross validation"""

##KFold Cross Validation
from sklearn.model_selection import KFold
kf = KFold(n_splits=5)
kf

for train_index, test_index in kf.split([1,2,3,4,5,6,7,8,9]):
    print(train_index, test_index)

def get_score(model, train_X, test_X, train_y, test_y):
    model.fit(train_X, train_y)
    return model.score(test_X, test_y)

get_score(RandomForestClassifier(n_estimators = 5, criterion='entropy', random_state = 20), train_X, test_X, train_y, test_y)

get_score(LogisticRegression(random_state= 42), train_X, test_X, train_y, test_y)

get_score(GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42), train_X, test_X, train_y, test_y)

get_score(XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200), train_X, test_X, train_y, test_y)

"""**Stratified KFold**"""

from sklearn.model_selection import StratifiedKFold
folds = StratifiedKFold(n_splits=5)

scores_rf = []
scores_lr = []
scores_gb = []
scores_xgb = []


for train_index, test_index in folds.split(digits.data,digits.target):
    train_X, test_X, train_y, test_y = digits.data[train_index],digits.data[test_index], \
                                      digits.target[train_index], digits.target[test_index]  
    scores_rf.append(get_score(RandomForestClassifier(n_estimators = 5, criterion='entropy', random_state = 20), train_X, test_X, train_y, test_y))
    scores_lr.append(get_score(LogisticRegression(random_state= 42), train_X, test_X, train_y, test_y))
    scores_gb.append(get_score(GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42), train_X, test_X, train_y, test_y))
    scores_xgb.append(get_score(XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200), train_X, test_X, train_y, test_y))

scores_rf

scores_lr

scores_gb

scores_xgb

"""Cross Val Score Function"""

##cross_val_score function
from sklearn.model_selection import cross_val_score

cross_val_score(RandomForestClassifier(n_estimators = 5, criterion='entropy', random_state = 20), digits.data, digits.target,cv=5)

cross_val_score(LogisticRegression(random_state= 42), digits.data, digits.target,cv=5)

cross_val_score(GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42), digits.data, digits.target,cv=5)

cross_val_score(XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200), digits.data, digits.target,cv=5)



"""Parameter tuning using K fold  cross Validation"""

scores1 = cross_val_score(RandomForestClassifier(n_estimators = 5, criterion='entropy', random_state = 20),digits.data, digits.target, cv=10)
np.average(scores1)

scores2 = cross_val_score(LogisticRegression(random_state= 42), digits.data, digits.target,cv=10)
np.average(scores2)

scores3 = cross_val_score(GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42), digits.data, digits.target,cv=10)
np.average(scores3)

scores4 = cross_val_score(XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200), digits.data, digits.target,cv=10)
np.average(scores4)





"""##Bagging (All Columns)"""

from sklearn.ensemble import BaggingClassifier

bg1 = BaggingClassifier(RandomForestClassifier(n_estimators = 5, criterion='entropy', random_state = 20),max_samples=0.5,max_features=7,n_estimators=20)
bg1.fit(train_X, train_y)

bg1.score(test_X,test_y)

bg2 = BaggingClassifier(LogisticRegression(random_state= 42),max_samples=0.5,max_features=7,n_estimators=20)
bg2.fit(train_X, train_y)

bg2.score(test_X,test_y)



"""##Boosting (All Columns)"""

##Gradient Boost
from sklearn.ensemble import AdaBoostClassifier
adb1 = AdaBoostClassifier(GradientBoostingClassifier(n_estimators=300,max_features=2,random_state=42),n_estimators = 5, learning_rate = 1)
adb1.fit(train_X, train_y)

adb1.score(test_X,test_y)





"""##Stacking(All Columns)"""

pip install six

import six

from sklearn.linear_model import LogisticRegression
from mlxtend.classifier import StackingClassifier

clf1=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
clf2=RandomForestClassifier(n_estimators = 5, criterion='entropy', random_state = 20)
clf3=AdaBoostClassifier(n_estimators=20, random_state=47)
log=LogisticRegression(random_state=42 )
sclf=StackingClassifier(classifiers=[clf1,clf2,clf3],use_probas=True,meta_classifier=log)

sclf.fit(train_X,train_y)

sclf.score(test_X,test_y)

clf1=SVC(C=10,kernel='poly',gamma=100)
clf2=RandomForestClassifier(n_estimators = 5, criterion='entropy', random_state = 20)
clf3=XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
log=LogisticRegression(random_state=42 )
sclf=StackingClassifier(classifiers=[clf1,clf2,clf3],use_probas=True,meta_classifier=log)



"""##Univariate feature Selection Method"""

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
from sklearn.model_selection import train_test_split

bestfeatures = SelectKBest(score_func=f_classif)

fit = bestfeatures.fit(x, y)

dfscores = pd.DataFrame(fit.scores_)
dfcolumns = pd.DataFrame(x.columns)

#concat two dataframes for better visualization
featurescore = pd.concat([dfcolumns,dfscores],axis=1)
featurescore.columns = ['Specs','Score']

featurescore

#print 10 best feature
featurescore.nlargest(10,'Score')

featurescore.nlargest(10,'Score').plot(kind='bar')

df_new = df.drop(['id','texture_mean','compactness_mean','smoothness_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se',
             'smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','texture_worst','compactness_worst','smoothness_worst',
             'symmetry_worst','fractal_dimension_worst'],axis='columns')



df_new

df_new.corr()

mask = np.triu(np.ones_like(df_new.corr()))

plt.figure(figsize=(18,14))
sns.heatmap(df_new.corr(), mask=mask, vmax=.3,linewidths=1, square=True)
plt.show()

x1 = df_new.drop(['diagnosis'],axis = 'columns')

x1

train_X,test_X,train_y,test_y =train_test_split(x1,y,random_state=42 ,test_size=0.2)
print('test_X',test_X.shape)
print('training_X',train_X.shape)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
train_X1 = sc.fit_transform(train_X)
test_X1 = sc.fit_transform(test_X)

train_X1.shape



"""## Fit Model(10 Columns)"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# def models(train_X1, train_y):
# 
# 
#   ##Support Vector Classifier 1
#   svm_model = SVC(C=10,kernel='poly',gamma=100)
#   svm_model.fit(train_X1, train_y) 
# 
#   ##Random Forest Classification 2
#   rf_model = RandomForestClassifier(n_estimators = 15, criterion='entropy', random_state = 25)
#   rf_model.fit(train_X1, train_y)
# 
#   ##Logistic Classification 3
#   lr_model = LogisticRegression(C=13.0,solver='liblinear', random_state=42)
#   lr_model.fit(train_X1, train_y)
# 
# 
#   ##GradientBoosting Classifier 5
#   gb_model=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
#   gb_model.fit(train_X1, train_y)
# 
#   ## AdaBoost Classifier 6
#   ada_model = AdaBoostClassifier(n_estimators = 50, random_state = 42)
#   ada_model.fit(train_X1, train_y)
# 
# 
#   ##XGBclassifier  7
#   xgb_model =XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
#   xgb_model.fit(train_X1, train_y)
# 
# 
#   print("Trainning Accuracty of Support Vector Classifier : ",svm_model.score(train_X1, train_y))
#   print("Trainning Accuracty of RandomForestClassifier Model : ",rf_model.score(train_X1, train_y))
#   print("Trainning Accuracty of Logistic Classification Model : ",lr_model.score(train_X1, train_y))
#   print("Trainning Accuracty of Gradient Boosting Classifier Model : ",gb_model.score(train_X1, train_y))
#   print("Trainning Accuracty of  AdaBoosting Classifier Model : ",ada_model.score(train_X1, train_y))
#   print("Trainning Accuracty of XGB classifier Model : ",xgb_model.score(train_X1, train_y))
# 
# 
#   return svm_model, rf_model, lr_model, gb_model, ada_model, xgb_model
# 
#

model = models(train_X1, train_y)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# from sklearn.metrics import confusion_matrix, classification_report, log_loss, cohen_kappa_score
# from sklearn import metrics
# 
# for i in range(len(model)):
#   print('Confusion matrix of model',i , 'is :')
#   cm = confusion_matrix(test_y, model[i].predict(test_X1))
#   TP = cm[0][0]
#   TN = cm[1][1]
#   FP = cm[0][1]
#   FN = cm[1][0]
#   print(cm)
#   print()
#   result1 = classification_report(test_y, model[i].predict(test_X1))
#   print("Classification Report : ", )
#   print (result1)
#   print()
#   var = ((TP + TN)/(TP + TN + FP + FN)) * 100 
#   print('Testing accuracy : ',var)
#   print('Sensitivity : ',TP/(TP+FN))
#   print('Specificity : ',TN/(TN+FP))
#   print('False positive rate : ',FP/(FP+TN))
#   print('False negative rate : ',FN/(FN+TP))
#   print('Negative predictive value : ',TN/(TN+FN))
#   print('False Discovery rate: ',FP/(TP+FP))
#   
# 
#   print()
#   print()
#   name = ['Support Vector Machine Model','Random Forest Model','Logistic Classification','GradientBoosting Classifier','AdaBoost Classifier','XGBclassifier']
#   col_value = ['blue','purple','orange','green','black','yellow']
#   model_accuracy = pd.Series(data=[var], index=[name[i]])
#   fig = plt.figure(figsize=(5,5))
#   width = 0.75
#   model_accuracy.sort_values().plot.bar(alpha=0.8, color=[col_value[i]])
#   plt.xticks(rotation=0)
#   plt.title('Model Accuracy')
#   plt.ylabel('Accuracy (%)')
#   plt.show()
#   print()
#   print()



"""##Voting with 10 Columns"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.ensemble import VotingClassifier
# 
# r = RandomForestClassifier(n_estimators = 15, criterion='entropy', random_state = 25)
# s = SVC(C=10,kernel='poly',gamma=100)
# l = LogisticRegression(random_state= 42)
# g = GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
# a = AdaBoostClassifier(n_estimators = 50, random_state = 42)
# x=XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
# evc = VotingClassifier(estimators=[('r',r),('s',s),('l',l),('g',g),('a',a),('x',x)], voting='hard')
# evc.fit(train_X1, train_y)
# evc.score(test_X1,test_y)
# print('Votting accuracy: ',evc.score(test_X1,test_y))

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# from sklearn.ensemble import VotingClassifier
# 
# g = GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
# l = LogisticRegression(random_state= 42)
# a = AdaBoostClassifier(n_estimators = 20, random_state = 42)
# x=XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
# evc = VotingClassifier(estimators=[('g',g), ('l',l),('a',a),('x',x)], voting='hard')
# evc.fit(train_X1, train_y)
# evc.score(test_X1,test_y)
# print('Votting accuracy: ',evc.score(test_X1,test_y))

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# from sklearn.ensemble import VotingClassifier
# 
# l = LogisticRegression(random_state= 42)
# a = AdaBoostClassifier(n_estimators = 20, random_state = 42)
# g=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
# evc = VotingClassifier(estimators=[('l',l), ('a',a),('g',g)], voting='hard')
# evc.fit(train_X1,train_y)
# evc.score(test_X1,test_y)
# print('Votting accuracy: ',evc.score(test_X1,test_y))





"""#AUC & ROC Curve(10 columns)

---


"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.metrics import roc_curve, roc_auc_score
# import sklearn.metrics as metrics
# 
# ##support Vector Machine Roc curve
# svm_model = SVC(probability=True)
# svm_model.fit(train_X1,train_y) 
# y_score1 = svm_model.predict_proba(test_X1)[:,1]
# ##Plot Receiving Operating Characteristic Curve
# ##Create true and false positive rate
# false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
# print('score of support vector machine: ',roc_auc_score(test_y, y_score1))
# #plot Roc curves
# plt.subplots(1, figsize=(5,5))
# plt.title('Support Vector Machine Roc Curve')
# plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Support Vector Machine")
# plt.plot([0,1], ls="--")
# plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.legend()
# plt.show()
# print()
# print() 
# ##Support Vector  Machine Aus curve
# svm = SVC(probability=True)
# svm.fit(train_X1,train_y)
# y_pred_proba=svm.predict(test_X1)
# ##Auc Curve
# plt.subplots(1, figsize=(5,5))
# y_pred_proba=svm.predict_proba(test_X1)[::,1]
# fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
# auc=metrics.roc_auc_score(test_y,y_pred_proba)
# plt.title('Support Vector  Machine Aus curve')
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
# plt.legend(loc=4)
# plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# from sklearn.metrics import roc_curve, roc_auc_score
# import sklearn.metrics as metrics
# 
# ##Random Forest Classification
# from sklearn.ensemble import RandomForestClassifier
# rf_model = RandomForestClassifier(n_estimators = 15, criterion='entropy', random_state = 25)
# rf_model.fit(train_X1, train_y)
# y_score1 = rf_model.predict_proba(test_X1)[:,1]
# ##Plot Receiving Operating Characteristic Curve
# ##Create true and false positive rate
# false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
# print('score of Random Forest Classification: ',roc_auc_score(test_y, y_score1))
# #plot Roc curves
# plt.subplots(1, figsize=(5,5))
# plt.title('Random Forest Classification Roc Curve')
# plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Random Forest Classification")
# plt.plot([0,1], ls="--")
# plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.legend()
# plt.show()
# print()
# print()
# ##Random Forest Classification Aus curve
# rf_model = RandomForestClassifier(n_estimators = 15, criterion='entropy', random_state = 25)
# rf_model.fit(train_X1, train_y)
# y_pred_proba=rf_model.predict(test_X1)
# ##Auc Curve
# plt.subplots(1, figsize=(5,5))
# y_pred_proba=rf_model.predict_proba(test_X1)[::,1]
# fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
# auc=metrics.roc_auc_score(test_y,y_pred_proba)
# plt.title('Random Forest Classification Aus curve')
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
# plt.legend(loc=4)
# plt.show()
#

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.metrics import roc_curve, roc_auc_score
# import sklearn.metrics as metrics
# 
# ##Logistic Regression Classification
# lr_model = LogisticRegression(random_state= 42)
# lr_model.fit(train_X1, train_y)
# y_score1 = lr_model.predict_proba(test_X1)[:,1]
# ##Plot Receiving Operating Characteristic Curve
# ##Create true and false positive rate
# false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
# print('score of Logistic Regression : ',roc_auc_score(test_y, y_score1))
# #plot Roc curves
# plt.subplots(1, figsize=(5,5))
# plt.title('Logistic Regression Roc Curve')
# plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Logistic Regression")
# plt.plot([0,1], ls="--")
# plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.legend()
# plt.show()
# print()
# print()
# ##Logistic Regression Aus curve
# lr_model = LogisticRegression(random_state= 42)
# lr_model.fit(train_X1, train_y)
# y_pred_proba=lr_model.predict(test_X1)
# ##Auc Curve
# plt.subplots(1, figsize=(5,5))
# y_pred_proba=rf_model.predict_proba(test_X)[::,1]
# fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
# auc=metrics.roc_auc_score(test_y,y_pred_proba)
# plt.title('Logistic Regression Aus curve')
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
# plt.legend(loc=4)
# plt.show()
#

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# from sklearn.metrics import roc_curve, roc_auc_score
# import sklearn.metrics as metrics
# 
# 
# ##Adaboost classifier      7
# ada_model = AdaBoostClassifier(n_estimators = 50, random_state = 42)
# ada_model.fit(train_X1, train_y)
# y_score1 = ada_model.predict_proba(test_X1)[:,1]
# ##Plot Receiving Operating Characteristic Curve
# ##Create true and false positive rate
# false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
# print('Adabost Classifier: ',roc_auc_score(test_y, y_score1))
# #plot Roc curves
# plt.subplots(1, figsize=(5,5))
# plt.title('Adabost Classifier')
# plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Adabost Classifier")
# plt.plot([0,1], ls="--")
# plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.legend()
# plt.show()
# print()
# print()
# ##Adabost classifier      7
# ada_model = AdaBoostClassifier(n_estimators = 50, random_state = 42)
# ada_model.fit(train_X1, train_y)
# y_pred_proba=ada_model.predict(test_X1)
# ##Auc Curve
# plt.subplots(1, figsize=(5,5))
# y_pred_proba=ada_model.predict_proba(test_X1)[::,1]
# fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
# auc=metrics.roc_auc_score(test_y,y_pred_proba)
# plt.title('Adabost Classifier')
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
# plt.legend(loc=4)
# plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.metrics import roc_curve, roc_auc_score
# import sklearn.metrics as metrics
# 
# 
# ##GradientBoostingClassifier 5
# gb_model=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
# gb_model.fit(train_X1, train_y)
# y_score1 = gb_model.predict_proba(test_X1)[:,1]
# ##Plot Receiving Operating Characteristic Curve
# ##Create true and false positive rate
# false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
# print('Gradient Boosting Classifier: ',roc_auc_score(test_y, y_score1))
# #plot Roc curves
# plt.subplots(1, figsize=(5,5))
# plt.title('Gradient Boosting Classifier')
# plt.plot(false_positive_rate1,true_positive_rate1 ,label= "GradientBoosting Classifier")
# plt.plot([0,1], ls="--")
# plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.legend()
# plt.show()
# print()
# print()
# ##GradientBoostingClassifier 5
# gb_model=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
# gb_model.fit(train_X1, train_y)
# y_pred_proba=gb_model.predict(test_X1)
# ##Auc Curve
# plt.subplots(1, figsize=(5,5))
# y_pred_proba=gb_model.predict_proba(test_X1)[::,1]
# fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
# auc=metrics.roc_auc_score(test_y,y_pred_proba)
# plt.title('GradientBoosting Classifier')
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
# plt.legend(loc=4)
# plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# from sklearn.metrics import roc_curve, roc_auc_score
# import sklearn.metrics as metrics
# 
# 
# ##XGB classifier      7
# xgb_model =XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 200)
# xgb_model.fit(train_X1, train_y)
# y_score1 = xgb_model.predict_proba(test_X1)[:,1]
# ##Plot Receiving Operating Characteristic Curve
# ##Create true and false positive rate
# false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
# print('XGB Classifier: ',roc_auc_score(test_y, y_score1))
# #plot Roc curves
# plt.subplots(1, figsize=(5,5))
# plt.title('XGB Classifier')
# plt.plot(false_positive_rate1,true_positive_rate1 ,label= "XGB Classifier")
# plt.plot([0,1], ls="--")
# plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.legend()
# plt.show()
# print()
# print()
# ##XGB classifier      7
# xgb_model =XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
# xgb_model.fit(train_X1, train_y)
# y_pred_proba=xgb_model.predict(test_X1)
# ##Auc Curve
# plt.subplots(1, figsize=(5,5))
# y_pred_proba=xgb_model.predict_proba(test_X1)[::,1]
# fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
# auc=metrics.roc_auc_score(test_y,y_pred_proba)
# plt.title('XGB Classifier')
# plt.ylabel('True Positive Rate')
# plt.xlabel('False Positive Rate')
# plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
# plt.legend(loc=4)
# plt.show()

"""##KFold Cross Validation (10 Columns)"""

##KFold Cross Validation
from sklearn.model_selection import KFold
kf = KFold(n_splits=5)
kf

for train_index, test_index in kf.split([1,2,3,4,5,6,7,8,9]):
    print(train_index, test_index)

def get_score(model, train_X1, test_X1, train_y, test_y):
    model.fit(train_X1, train_y)
    return model.score(test_X1, test_y)

get_score(RandomForestClassifier(n_estimators = 15, criterion='entropy', random_state = 25), train_X1, test_X1, train_y, test_y)

get_score(LogisticRegression(C=13.0,solver='liblinear', random_state=42), train_X1, test_X1, train_y, test_y)

get_score(GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42), train_X1, test_X1, train_y, test_y)

get_score(XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200), train_X1, test_X1, train_y, test_y)

"""**Stratified KFold**"""

from sklearn.model_selection import StratifiedKFold
folds = StratifiedKFold(n_splits=5)

scores_rf = []
scores_lr = []
scores_gb = []
scores_xgb = []


for train_index, test_index in folds.split(digits.data,digits.target):
    train_X1, test_X1, train_y, test_y = digits.data[train_index],digits.data[test_index], \
                                      digits.target[train_index], digits.target[test_index]  
    scores_rf.append(get_score(RandomForestClassifier(n_estimators = 5, criterion='entropy', random_state = 20), train_X1, test_X1, train_y, test_y))
    scores_lr.append(get_score(LogisticRegression(random_state= 42), train_X1, test_X1, train_y, test_y))
    scores_gb.append(get_score(GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42), train_X1, test_X1, train_y, test_y))
    scores_xgb.append(get_score(XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200), train_X1, test_X1, train_y, test_y))

scores_rf

scores_lr

scores_gb

scores_xgb

"""**Cross Val function**"""

##cross_val_score function
from sklearn.model_selection import cross_val_score

cross_val_score(RandomForestClassifier(n_estimators = 15, criterion='entropy', random_state = 25), digits.data, digits.target,cv=5)

cross_val_score(LogisticRegression(random_state= 42), digits.data, digits.target,cv=5)

cross_val_score(GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42), digits.data, digits.target,cv=5)

cross_val_score(XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200), digits.data, digits.target,cv=5)

"""**Parameter tuning using K fold cross Validation**"""

scores1 = cross_val_score(RandomForestClassifier(n_estimators = 15, criterion='entropy', random_state =25),digits.data, digits.target, cv=10)
np.average(scores1)

scores2 = cross_val_score(LogisticRegression(random_state= 42),digits.data, digits.target, cv=10)
np.average(scores2)

scores3 = cross_val_score(GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42),digits.data, digits.target, cv=10)
np.average(scores3)

scores4 = cross_val_score(XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200),digits.data, digits.target, cv=10)
np.average(scores4)

"""## Bagging (10 Columns)"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.ensemble import BaggingClassifier
# 
# bgA = BaggingClassifier(RandomForestClassifier(n_estimators = 15, criterion='entropy', random_state = 25),max_samples=0.9,max_features=9,n_estimators=42)
# bgA.fit(train_X1, train_y)

bgA.score(test_X1,test_y)

bgA2 = BaggingClassifier(LogisticRegression(random_state= 42),max_samples=0.8,max_features=9,n_estimators=42)
bgA2.fit(train_X1, train_y)

bgA2.score(test_X1,test_y)

"""##Boosting(10 Columns)"""

##Gradient Boost
from sklearn.ensemble import AdaBoostClassifier
adbA = AdaBoostClassifier(GradientBoostingClassifier(n_estimators=300,max_features=2,random_state=42),n_estimators = 5, learning_rate = 1)
adbA.fit(train_X1, train_y)

adbA.score(test_X1,test_y)





"""#PCA"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(df)

scaled_data = scaler.transform(df)

from sklearn.decomposition import PCA
pca = PCA(n_components=2)

pca.fit(scaled_data)

x_pca = pca.transform(scaled_data)

scaled_data.shape, x_pca.shape

pca_df = pd.DataFrame(data = x_pca, columns = ['principal component 1', 'principal component 2'])
pca_df



"""visualising PCA

#Hyper Parameter Tuning

**Random Forest**
"""

from sklearn.model_selection import GridSearchCV

rfc_param = {  'bootstrap': [True],'max_depth': [5, 10, None], 'max_features': ['auto', 'log2'], 'n_estimators': [5, 6, 7, 8, 9, 10, 11, 12, 13, 15]}

rfc=RandomForestClassifier(n_estimators=2,criterion='entropy',random_state=30)

g_search = GridSearchCV(estimator = rfc, param_grid = rfc_param, cv = 15, n_jobs = 1, verbose = 0, return_train_score=True)

g_search.fit(train_X1, train_y);

print(g_search.best_params_)

print(g_search.score(train_X1, train_y))

g_search.best_score_



"""**SVC**"""

svc_param = {  'degree': [1,2,3],'gamma': ['scale', 'auto']}

svc = SVC(C=10,kernel='poly',gamma=100)

g_search1 = GridSearchCV(estimator = svc, param_grid = svc_param, cv = 15, n_jobs = 1, verbose = 0, return_train_score=True)

g_search1.fit(train_X1, train_y);

print(g_search1.best_params_)

print(g_search1.score(train_X1, train_y))

g_search1.best_score_



"""**Logistic Regression**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# log_param = {  'penalty':['l1', 'l2', 'elasticnet', 'none'], 'multi_class':['auto', 'ovr']}

lr= LogisticRegression(C=13.0,solver='liblinear', random_state=42)
g_search2 = GridSearchCV(estimator = lr, param_grid = log_param, cv = 15, n_jobs = 1, verbose = 0, return_train_score=True)

g_search2.fit(train_X1, train_y);

print(g_search2.best_params_)

print(g_search2.score(train_X1, train_y))

g_search2.best_score_

"""**Gradient Boosting**"""

gb_param= {  'max_depth': [1,2,3,4,5],'max_features': ['auto', 'sqrt', 'log2'], 'max_features': ['auto', 'log2'], 'n_estimators': [5, 6, 7, 8, 9, 10, 11, 12, 13, 15]}

gb= GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
g_search3 = GridSearchCV(estimator = gb, param_grid = gb_param, cv = 15, n_jobs = 1, verbose = 0, return_train_score=True)

g_search3.fit(train_X1, train_y);

print(g_search3.best_params_)

print(g_search3.score(train_X1, train_y))

g_search3.best_score_

"""**AdaBoost**"""

ada_param= {  'algorithm': ['SAMME','SAMME.R'], 'n_estimators': [5, 10,15,20,25]}

ada= AdaBoostClassifier(n_estimators = 50, random_state = 42)
g_search4 = GridSearchCV(estimator = ada, param_grid = ada_param, cv = 15, n_jobs = 1, verbose = 0, return_train_score=True)

g_search4.fit(train_X1, train_y);

print(g_search4.best_params_)

print(g_search4.score(train_X1, train_y))

g_search4.best_score_

"""**XGB**"""