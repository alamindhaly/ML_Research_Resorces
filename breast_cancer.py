# -*- coding: utf-8 -*-
"""Breast Cancer

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J_r07cmLKqALUm-yBpN_p5AwOO7SR6wh
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import warnings
warnings.filterwarnings('ignore')

from google.colab import files
files.upload()

df_file = pd.read_csv("/content/data.csv")

df_file

df_file

df_file.drop(['Unnamed: 32'], axis ='columns', inplace = True)

df_file.isna().values.any()

dummy = pd.get_dummies(df_file['diagnosis'])

df_file2 = pd.concat((df_file,dummy),axis=1)

df_file2

df_file2=df_file2.drop(['diagnosis'],axis='columns')

df_file2

dff=df_file2.drop(['M'],axis=1)

dff

df=dff.rename(columns={'B':'diagnosis'})

df.head(10)

df.columns

"""##Train Test Split"""

x = df.drop(['diagnosis'],axis='columns')

x

y = df['diagnosis']

y

from sklearn.model_selection import train_test_split

train_X,test_X,train_y,test_y =train_test_split(x,y,random_state=42 ,test_size=0.2)
print('test_X',test_X.shape)
print('training_X',train_X.shape)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
train_X = sc.fit_transform(train_X)
test_X = sc.fit_transform(test_X)



"""## Fit Model"""

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import AdaBoostClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import BaggingClassifier, VotingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_digits
digits = load_digits()

# Commented out IPython magic to ensure Python compatibility.
# ##SVC 1
# %%time
# svc=SVC(C=10,kernel='poly',gamma=100)
# svc.fit(train_X, train_y)
# svc.score(test_X,test_y)

# Commented out IPython magic to ensure Python compatibility.
# ##random 2
# %%time
# forest=RandomForestClassifier(n_estimators = 5, criterion='entropy', random_state = 20)
# forest.fit(train_X, train_y)
# forest.score(test_X,test_y)

# Commented out IPython magic to ensure Python compatibility.
# ##xgb 3
# %%time
# xgb_model =XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
# xgb_model.fit(train_X, train_y)
# xgb_model.score(test_X,test_y)

# Commented out IPython magic to ensure Python compatibility.
# ##LRC
# %%time
# lr_model = LogisticRegression(random_state= 42)
# lr_model.fit(train_X, train_y)
# lr_model.score(test_X,test_y)

# Commented out IPython magic to ensure Python compatibility.
# ##ada 4
# %%time
#   ada_model = AdaBoostClassifier(n_estimators = 20, random_state = 42)
# ada_model.fit(train_X, train_y)
# ada_model.score(test_X,test_y)

# Commented out IPython magic to ensure Python compatibility.
# ##grd  5
# %%time
#   gb_model=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
# gb_model.fit(train_X, train_y)
# gb_model.score(test_X,test_y)

# Commented out IPython magic to ensure Python compatibility.
# Decision Tree classifier  6  
#   %%time
classifier= DecisionTreeClassifier(criterion='entropy', random_state=0)  
classifier.fit(train_X, train_y)
classifier.score(test_X,test_y)

def models(train_X, train_y):


  ##Support Vector Classifier 1
  
  svm_model = SVC(C=10,kernel='poly',gamma=100)
  svm_model.fit(train_X, train_y) 

  ##Random Forest Classification 2
 
  rf_model = RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 20)
  rf_model.fit(train_X, train_y)

  ##ada 3

  ada_model = AdaBoostClassifier(n_estimators = 20, random_state = 42)
  ada_model.fit(train_X, train_y)

##Logistic Classification

 ##lr_model = LogisticRegression(random_state= 42)
 ##lr_model.fit(train_X, train_y)


  ##Decision Tree Classifier 4
  
  dt_model = DecisionTreeClassifier()
  dt_model.fit(train_X, train_y)

  ##GradientBoostingClassifier 5
  
  gb_model=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
  gb_model.fit(train_X, train_y)


  ##XGBclassifier  6
  
  xgb_model =XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
  xgb_model.fit(train_X, train_y)

  ##GradientBoostingClassifier 5
  
  lr_model = LogisticRegression(random_state= 42)
  lr_model.fit(train_X, train_y)




  print("Trainning Accuracty of Support Vector Classifier : ",svm_model.score(train_X, train_y))
  print("Trainning Accuracty of RandomForestClassifier Model : ",rf_model.score(train_X, train_y))
  print("Trainning Accuracty of RandomForestClassifier Model : ",ada_model.score(train_X, train_y))
  ##print("Trainning Accuracty of Logistic Classification Model : ",lr_model.score(train_X, train_y))
  print("Trainning Accuracty of Decision Tree Classifier Model : ",dt_model.score(train_X, train_y))
  print("Trainning Accuracty of Gradient Boosting Classifier Model : ",gb_model.score(train_X, train_y))
  print("Trainning Accuracty of XGB classifier Model : ",xgb_model.score(train_X, train_y))
  print("Trainning Accuracty of Logistic Classification Model : ",lr_model.score(train_X, train_y))


  return svm_model, rf_model, ada_model,dt_model, gb_model, xgb_model,lr_model

model = models(train_X, train_y)

from sklearn.metrics import confusion_matrix, classification_report, log_loss, cohen_kappa_score
from sklearn import metrics

for i in range(len(model)):
  print('Confusion matrix of model',i , 'is :')
  cm = confusion_matrix(test_y, model[i].predict(test_X))
  TP = cm[0][0]
  TN = cm[1][1]
  FP = cm[0][1]
  FN = cm[1][0]
  print(cm)
  print()
  result1 = classification_report(test_y, model[i].predict(test_X))
  print("Classification Report : ", )
  print (result1)
  print()
  var = ((TP + TN)/(TP + TN + FP + FN)) * 100 
  print('Testing accuracy : ',var)
  print('Sensitivity : ',TP/(TP+FN))
  print('Specificity : ',TN/(TN+FP))
  print('False positive rate : ',FP/(FP+TN))
  print('False negative rate : ',FN/(FN+TP))
  print('Negative predictive value : ',TN/(TN+FN))
  print('False Discovery rate: ',FP/(TP+FP))
  print('Mean Absolute Error: ',metrics.mean_absolute_error(test_y,model[i].predict(test_X)))
  print('Mean Squared Error: ',metrics.mean_squared_error(test_y,model[i].predict(test_X)))
  print('Root Mean Squared Error: ',np.sqrt(metrics.mean_squared_error(test_y,model[i].predict(test_X))))
  print('Log Loss: ',metrics.log_loss(test_y,model[i].predict(test_X)))
  print('Cohen_Kappa_Score: ',cohen_kappa_score(test_y,model[i].predict(test_X)))
  

  print()
  print()
  name = ['Support Vector Machine Model','Random Forest Model','Decision Tree Classifier','GradientBoosting Classifier','AdaBoost Classifier','XGBclassifier', 'Logistic Regression']
  col_value = ['blue','purple','orange','green','black','yellow', 'red']
  model_accuracy = pd.Series(data=[var], index=[name[i]])
  fig = plt.figure(figsize=(5,5))
  width = 0.75
  model_accuracy.sort_values().plot.bar(alpha=0.8, color=[col_value[i]])
  plt.xticks(rotation=0)
  plt.title('Model Accuracy')
  plt.ylabel('Accuracy (%)')
  plt.show()
  print()
  print()



"""## Voting """

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.ensemble import VotingClassifier
# a = AdaBoostClassifier(n_estimators = 20, random_state = 42)
# r = RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 20)
# s = SVC(C=10,kernel='poly',gamma=100)
# d = DecisionTreeClassifier()
# g = GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
# x = XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
# evc = VotingClassifier(estimators=[('a',a),('r',r),('s',s),('d',d),('g',g),('x',x)], voting='hard')
# evc.fit(train_X,train_y)
# evc.score(test_X,test_y)
# print('Votting accuracy: ',evc.score(test_X,test_y))

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.ensemble import VotingClassifier
# 
# r = RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 20)
# s = SVC(C=10,kernel='poly',gamma=100)
# d = DecisionTreeClassifier()
# g = GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
# x = XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
# evc = VotingClassifier(estimators=[('r',r),('s',s),('d',d),('g',g),('x',x)], voting='hard')
# evc.fit(train_X,train_y)
# evc.score(test_X,test_y)
# print('Votting accuracy: ',evc.score(test_X,test_y))

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.ensemble import VotingClassifier
# a = AdaBoostClassifier(n_estimators = 20, random_state = 42)
# r = RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 20)
# s = SVC(C=10,kernel='poly',gamma=100)
# g = GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
# x = XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
# evc = VotingClassifier(estimators=[('a',a),('r',r),('s',s),('g',g),('x',x)], voting='hard')
# evc.fit(train_X,train_y)
# evc.score(test_X,test_y)
# print('Votting accuracy: ',evc.score(test_X,test_y))

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.ensemble import VotingClassifier
# a = AdaBoostClassifier(n_estimators = 20, random_state = 42)
# s = SVC(C=10,kernel='poly',gamma=100)
# g = GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
# x = XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
# evc = VotingClassifier(estimators=[('a',a),('s',s),('g',g),('x',x)], voting='hard')
# evc.fit(train_X,train_y)
# evc.score(test_X,test_y)
# print('Votting accuracy: ',evc.score(test_X,test_y))

# Commented out IPython magic to ensure Python compatibility.
# %%time
# s = SVC(C=10,kernel='poly',gamma=100)
# x=XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
# d = DecisionTreeClassifier()
# evc = VotingClassifier(estimators=[('s',s),('g',g),('x',x),('d',d)], voting='hard')
# evc.fit(train_X,train_y)
# evc.score(test_X,test_y)
# print('Votting accuracy: ',evc.score(test_X,test_y))

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.ensemble import VotingClassifier
# 
# s = SVC(C=10,kernel='poly',gamma=100)
# d = DecisionTreeClassifier()
# g=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
# evc = VotingClassifier(estimators=[('s',s), ('d',d),('g',g)], voting='hard')
# evc.fit(train_X,train_y)
# evc.score(test_X,test_y)
# print('Votting accuracy: ',evc.score(test_X,test_y))



"""##AUC & ROC Curve"""



from sklearn.metrics import roc_curve, roc_auc_score
import sklearn.metrics as metrics

##support Vector Machine Roc curve
svm_model = SVC(probability=True)
svm_model.fit(train_X, train_y) 
y_score1 = svm_model.predict_proba(test_X)[:,1]
##Plot Receiving Operating Characteristic Curve
##Create true and false positive rate
false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
print('score of support vector machine: ',roc_auc_score(test_y, y_score1))
#plot Roc curves
plt.subplots(1, figsize=(5,5))
plt.title('Support Vector Machine Roc Curve')
plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Support Vector Machine")
plt.plot([0,1], ls="--")
plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()
print()
print() 
##Support Vector  Machine Aus curve
svm = SVC(probability=True)
svm.fit(train_X,train_y)
y_pred_proba=svm.predict(test_X)
##Auc Curve
plt.subplots(1, figsize=(5,5))
y_pred_proba=svm.predict_proba(test_X)[::,1]
fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
auc=metrics.roc_auc_score(test_y,y_pred_proba)
plt.title('Support Vector  Machine Aus curve')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score
import sklearn.metrics as metrics

##Random Forest Classification
from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 20)
rf_model.fit(train_X, train_y)
y_score1 = rf_model.predict_proba(test_X)[:,1]
##Plot Receiving Operating Characteristic Curve
##Create true and false positive rate
false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
print('score of Random Forest Classification: ',roc_auc_score(test_y, y_score1))
#plot Roc curves
plt.subplots(1, figsize=(5,5))
plt.title('Random Forest Classification Roc Curve')
plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Random Forest Classification")
plt.plot([0,1], ls="--")
plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()
print()
print()
##Random Forest Classification Aus curve
rf_model = RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 20)
rf_model.fit(train_X, train_y)
y_pred_proba=rf_model.predict(test_X)
##Auc Curve
plt.subplots(1, figsize=(5,5))
y_pred_proba=rf_model.predict_proba(test_X)[::,1]
fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
auc=metrics.roc_auc_score(test_y,y_pred_proba)
plt.title('Random Forest Classification Aus curve')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score
import sklearn.metrics as metrics


##Decision Tree classifier 
classifier= DecisionTreeClassifier(criterion='entropy', random_state=0)
classifier.fit(train_X, train_y)
y_score1 = classifier.predict_proba(test_X)[:,1]
##Plot Receiving Operating Characteristic Curve
##Create true and false positive rate
false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
print('score of Decision Tree classifier  : ',roc_auc_score(test_y, y_score1))
#plot Roc curves
plt.subplots(1, figsize=(5,5))
plt.title('Decision Tree classifier  Roc Curve')
plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Decision Tree classifier")
plt.plot([0,1], ls="--")
plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()
print()
print()


##Decision Tree classifier 
classifier= DecisionTreeClassifier(criterion='entropy', random_state=0)
classifier.fit(train_X, train_y)
y_score1 = classifier.predict_proba(test_X)[:,1] 


##Auc Curve
plt.subplots(1, figsize=(5,5))
y_pred_proba=rf_model.predict_proba(test_X)[::,1]
fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
auc=metrics.roc_auc_score(test_y,y_pred_proba)
plt.title('Decision Tree classifier  Aus curve')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score
import sklearn.metrics as metrics


##GradientBoostingClassifier 5
gb_model=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
gb_model.fit(train_X, train_y)
y_score1 = gb_model.predict_proba(test_X)[:,1]
##Plot Receiving Operating Characteristic Curve
##Create true and false positive rate
false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
print('Gradient Boosting Classifier: ',roc_auc_score(test_y, y_score1))
#plot Roc curves
plt.subplots(1, figsize=(5,5))
plt.title('Gradient Boosting Classifier')
plt.plot(false_positive_rate1,true_positive_rate1 ,label= "GradientBoosting Classifier")
plt.plot([0,1], ls="--")
plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()
print()
print()
##GradientBoostingClassifier 5
gb_model=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
gb_model.fit(train_X, train_y)
y_pred_proba=gb_model.predict(test_X)
##Auc Curve
plt.subplots(1, figsize=(5,5))
y_pred_proba=gb_model.predict_proba(test_X)[::,1]
fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
auc=metrics.roc_auc_score(test_y,y_pred_proba)
plt.title('GradientBoosting Classifier')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score
import sklearn.metrics as metrics


##Adaboost classifier      7
ada_model = AdaBoostClassifier(n_estimators = 20, random_state = 42)
ada_model.fit(train_X, train_y)
y_score1 = ada_model.predict_proba(test_X)[:,1]
##Plot Receiving Operating Characteristic Curve
##Create true and false positive rate
false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
print('Adabost Classifier: ',roc_auc_score(test_y, y_score1))
#plot Roc curves
plt.subplots(1, figsize=(5,5))
plt.title('Adabost Classifier')
plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Adabost Classifier")
plt.plot([0,1], ls="--")
plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()
print()
print()
##Adabost classifier      7
ada_model = AdaBoostClassifier(n_estimators = 20, random_state = 42)
ada_model.fit(train_X, train_y)
y_pred_proba=ada_model.predict(test_X)
##Auc Curve
plt.subplots(1, figsize=(5,5))
y_pred_proba=ada_model.predict_proba(test_X)[::,1]
fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
auc=metrics.roc_auc_score(test_y,y_pred_proba)
plt.title('Adabost Classifier')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score
import sklearn.metrics as metrics


##XGB classifier      7
xgb_model =XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 200)
xgb_model.fit(train_X, train_y)
y_score1 = xgb_model.predict_proba(test_X)[:,1]
##Plot Receiving Operating Characteristic Curve
##Create true and false positive rate
false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
print('XGB Classifier: ',roc_auc_score(test_y, y_score1))
#plot Roc curves
plt.subplots(1, figsize=(5,5))
plt.title('XGB Classifier')
plt.plot(false_positive_rate1,true_positive_rate1 ,label= "XGB Classifier")
plt.plot([0,1], ls="--")
plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()
print()
print()
##XGB classifier      7
xgb_model =XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
xgb_model.fit(train_X, train_y)
y_pred_proba=xgb_model.predict(test_X)
##Auc Curve
plt.subplots(1, figsize=(5,5))
y_pred_proba=xgb_model.predict_proba(test_X)[::,1]
fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
auc=metrics.roc_auc_score(test_y,y_pred_proba)
plt.title('XGB Classifier')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score
import sklearn.metrics as metrics


##Logistic Regression classifier      7
lr_model =LogisticRegression(random_state= 42)
lr_model.fit(train_X, train_y)
y_score1 = lr_model.predict_proba(test_X)[:,1]
##Plot Receiving Operating Characteristic Curve
##Create true and false positive rate
false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
print('Logistic Regression Classifier: ',roc_auc_score(test_y, y_score1))
#plot Roc curves
plt.subplots(1, figsize=(5,5))
plt.title('Logistic Regression Classifier')
plt.plot(false_positive_rate1,true_positive_rate1 ,label= "XGB Classifier")
plt.plot([0,1], ls="--")
plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()
print()
print()
##XGB classifier      7
lr_model =LogisticRegression(random_state= 42)
lr_model.fit(train_X, train_y)
y_pred_proba=lr_model.predict(test_X)
##Auc Curve
plt.subplots(1, figsize=(5,5))
y_pred_proba=lr_model.predict_proba(test_X)[::,1]
fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
auc=metrics.roc_auc_score(test_y,y_pred_proba)
plt.title('Logistic Regression Classifier')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()



"""##KFold Cross Validation"""

##KFold Cross Validation
from sklearn.model_selection import KFold
kf = KFold(n_splits=5)
kf

for train_index, test_index in kf.split([1,2,3,4,5,6,7,8,9]):
    print(train_index, test_index)

"""#to copy"""

def get_score(model, train_X, test_X, train_y, test_y):
    model.fit(train_X, train_y)
    return model.score(test_X, test_y)

get_score(SVC(), train_X, test_X, train_y, test_y)

get_score(RandomForestClassifier(), train_X, test_X, train_y, test_y)

get_score(DecisionTreeClassifier(), train_X, test_X, train_y, test_y)

get_score(GradientBoostingClassifier(n_estimators=300,max_features=2,random_state=42), train_X, test_X, train_y, test_y)

get_score(XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200), train_X, test_X, train_y, test_y)

get_score(AdaBoostClassifier(),train_X, test_X, train_y, test_y)

get_score(LogisticRegression(),train_X, test_X, train_y, test_y)

"""StratifiedKFold"""

from sklearn.model_selection import StratifiedKFold
folds = StratifiedKFold(n_splits=5)

scores_svm = []
scores_rf = []
scores_decision = []
scores_gradient = []
scores_lr=[]
scores_ab=[]




for train_index, test_index in folds.split(digits.data,digits.target):
    train_X, test_X, train_y, test_y = digits.data[train_index],digits.data[test_index], \
                                      digits.target[train_index], digits.target[test_index]  
    scores_svm.append(get_score(SVC(C=10,kernel='poly',gamma='auto'), train_X, test_X, train_y, test_y))
    scores_rf.append(get_score(RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 14), train_X, test_X, train_y, test_y))
    scores_decision.append(get_score(DecisionTreeClassifier(), train_X, test_X, train_y, test_y))
    ##scores_gradient.append(get_score(GradientBoostingClassifier(), train_X, test_X, train_y, test_y))
    ##scores_lr.append(get_score(LogisticRegression(random_state= 42)), train_X, test_X, train_y, test_y))
    ##scores_ab.append(get_score(AdaBoostClassifier(n_estimators = 20, random_state = 42)), train_X, test_X, train_y, test_y))

scores_svm

scores_rf

scores_decision

scores_gradient

scores_ab

scores_lr

"""cross_val_score function"""

##cross_val_score function
from sklearn.model_selection import cross_val_score

cross_val_score(SVC(C=10,kernel='poly',gamma='auto'), digits.data, digits.target,cv=5)

cross_val_score(RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 14), digits.data, digits.target,cv=5)

cross_val_score(DecisionTreeClassifier(), digits.data, digits.target,cv=5)

cross_val_score(GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42), digits.data, digits.target,cv=5)

cross_val_score(LogisticRegression(random_state= 42), digits.data, digits.target,cv=5)

cross_val_score(AdaBoostClassifier(n_estimators = 20, random_state = 42), digits.data, digits.target,cv=5)

"""##Parameter tunning using k fold cross validation"""

scores1 = cross_val_score(SVC(C=10,kernel='poly',gamma='auto'), digits.data, digits.target,cv=5)
np.average(scores1)

scores2 = cross_val_score(RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 14), digits.data, digits.target,cv=5)
np.average(scores2)

scores3 = cross_val_score(DecisionTreeClassifier(), digits.data, digits.target,cv=5)
np.average(scores3)

scores4 = cross_val_score(GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42), digits.data, digits.target,cv=5)
np.average(scores4)

scores5 = cross_val_score(XGBClassifier( colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200), digits.data, digits.target,cv=5)
np.average(scores5)

scores6 = cross_val_score(AdaBoostClassifier( n_estimators = 20, random_state = 42), digits.data, digits.target,cv=5)
np.average(scores6)

scores7 = cross_val_score(LogisticRegression(random_state= 42), digits.data, digits.target,cv=5)
np.average(scores7)



"""##Bagging """

# Commented out IPython magic to ensure Python compatibility.
# ## Random Forest
# %%time
# bgr = BaggingClassifier(RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 20), max_samples= 0.5, max_features = 7, n_estimators = 30)
# bgr.fit(train_X, train_y)
#

# Commented out IPython magic to ensure Python compatibility.
# %%time
# bgr.score(test_X,test_y)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# bgr.score(train_X,train_y)

# Commented out IPython magic to ensure Python compatibility.
# ## Decision Tree
# %%time
# bgd = BaggingClassifier(RandomForestClassifier(), max_samples= 0.5, max_features = 7, n_estimators = 30)
# bgd.fit(train_X, train_y)
#

# Commented out IPython magic to ensure Python compatibility.
# %%time
# bgd.score(test_X,test_y)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# bgd.score(train_X,train_y)



"""##Boosting (All Columns)"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# ##Gradient Boost
# from sklearn.ensemble import AdaBoostClassifier
# adb1 = AdaBoostClassifier(GradientBoostingClassifier(n_estimators=300,max_features=2,random_state=42),n_estimators = 5, learning_rate = 1)
# adb1.fit(train_X, train_y)

adb1.score(test_X,test_y)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# ##adaboost 
# from sklearn.ensemble import AdaBoostClassifier
# adb2 = AdaBoostClassifier(AdaBoostClassifier(n_estimators = 20, random_state = 42))
# adb2.fit(train_X, train_y)

adb2.score(test_X,test_y)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# ##XGB
# from sklearn.ensemble import AdaBoostClassifier
# adb3 = AdaBoostClassifier(XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200))
# adb3.fit(train_X, train_y)

adb3.score(test_X,test_y)





"""#Univariate Feature Selection"""

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
from sklearn.model_selection import train_test_split

bestfeatures = SelectKBest(score_func=f_classif)

fit = bestfeatures.fit(x,y)

dfscores = pd.DataFrame(fit.scores_)
dfcolumns = pd.DataFrame(x.columns)

#concat two dataframes for better visualization
featurescore = pd.concat([dfcolumns,dfscores],axis=1)
featurescore.columns = ['Specs','Score']

featurescore



"""###10 Most importance Columns"""

#print 10 best feature
featurescore.nlargest(10,'Score')

featurescore.nlargest(10,'Score').plot(kind='bar')

"""Drop less important feature"""

data_new = df.drop(['texture_se','symmetry_se','smoothness_se','fractal_dimension_se'], axis=1)

data_new

data_new.corr()

mask = np.triu(np.ones_like(data_new.corr()))

plt.figure(figsize=(20,12))
sns.heatmap(data_new.corr(), mask=mask, vmax=.3,linewidths=1, square=True)
plt.show()



data_X_new = data_new.drop(['smoothness_mean','symmetry_mean','radius_mean','area_mean','concavity_worst', 'concave points_worst' ],axis=1)

data_X_new

y

from sklearn.model_selection import train_test_split 
train_X,test_X,train_y,test_y =train_test_split(data_X_new,y,random_state=2 ,test_size=0.3)
print('test_X',test_X.shape)
print('training_X',train_X.shape)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
train_X_new = sc.fit_transform(train_X)
test_X_new= sc.fit_transform(test_X)

train_X_new.shape

"""###For finding Trainning Accuracy 10 most importance Columns"""

def models(train_X, train_y):


  ##Support Vector Classifier 1
  
  svm_model = SVC(C=10,kernel='poly',gamma=100)
  svm_model.fit(train_X, train_y) 

  ##Random Forest Classification 2
 
  rf_model = RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 20)
  rf_model.fit(train_X, train_y)

  ##ada 3

  ada_model = AdaBoostClassifier(n_estimators = 20, random_state = 42)
  ada_model.fit(train_X, train_y)

##Logistic Classification

 ##lr_model = LogisticRegression(random_state= 42)
 ##lr_model.fit(train_X, train_y)


  ##Decision Tree Classifier 4
  
  dt_model = DecisionTreeClassifier()
  dt_model.fit(train_X, train_y)

  ##GradientBoostingClassifier 5
  
  gb_model=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
  gb_model.fit(train_X, train_y)


  ##XGBclassifier  6
  
  xgb_model =XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
  xgb_model.fit(train_X, train_y)

  ##GradientBoostingClassifier 5
  
  lr_model = LogisticRegression(random_state= 42)
  lr_model.fit(train_X, train_y)



  ##print("Trainning Accuracty of Support Vector Classifier : ",svm_model.score(train_X_new, train_y))
  ##print("Trainning Accuracty of RandomForestClassifier Model : ",rf_model.score(train_X_new, train_y))
  ##print("Trainning Accuracty of Decision Tree Classifier Model : ",dt_model.score(train_X_new, train_y))
  ##print("Trainning Accuracty of Gradient Boosting Classifier Model : ",gb_model.score(train_X_new, train_y))
  ##print("Trainning Accuracty of XGB classifier Model : ",xgb_model.score(train_X_new, train_y))
  print("Trainning Accuracty of Support Vector Classifier : ",svm_model.score(train_X_new, train_y))
  print("Trainning Accuracty of RandomForestClassifier Model : ",rf_model.score(train_X_new, train_y))
  print("Trainning Accuracty of AdaBoostClassifier Model : ",ada_model.score(train_X_new, train_y))
  ##print("Trainning Accuracty of Logistic Classification Model : ",lr_model.score(train_X_new, train_y))
  print("Trainning Accuracty of Decision Tree Classifier Model : ",dt_model.score(train_X_new, train_y))
  print("Trainning Accuracty of Gradient Boosting Classifier Model : ",gb_model.score(train_X_new, train_y))
  print("Trainning Accuracty of XGB classifier Model : ",xgb_model.score(train_X_new, train_y))
  print("Trainning Accuracty of Logistic Classification Model : ",lr_model.score(train_X_new, train_y))


  return svm_model, rf_model, ada_model,dt_model, gb_model, xgb_model,lr_model

model = models(train_X_new, train_y)

"""##Get Accuracy, precision, recall, f1-score For 10 Columns"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.metrics import confusion_matrix, classification_report, log_loss, cohen_kappa_score
# from sklearn import metrics
# 
# for i in range(len(model)):
#   print('Confusion matrix of model',i , 'is :')
#   cm = confusion_matrix(test_y, model[i].predict(test_X_new))
#   TP = cm[0][0]
#   TN = cm[1][1]
#   FP = cm[0][1]
#   FN = cm[1][0]
#   print(cm)
#   print()
#   result1 = classification_report(test_y, model[i].predict(test_X_new))
#   print("Classification Report : ", )
#   print (result1)
#   print()
#   var = ((TP + TN)/(TP + TN + FP + FN)) * 100 
#   print('Testing accuracy : ',var)
#   print('Sensitivity : ',TP/(TP+FN))
#   print('Specificity : ',TN/(TN+FP))
#   print('False positive rate : ',FP/(FP+TN))
#   print('False negative rate : ',FN/(FN+TP))
#   print('Negative predictive value : ',TN/(TN+FN))
#   print('False Discovery rate: ',FP/(TP+FP))
#   print('Mean Absolute Error: ',metrics.mean_absolute_error(test_y,model[i].predict(test_X_new)))
#   print('Mean Squared Error: ',metrics.mean_squared_error(test_y,model[i].predict(test_X_new)))
#   print('Root Mean Squared Error: ',np.sqrt(metrics.mean_squared_error(test_y,model[i].predict(test_X_new))))
#   print('Log Loss: ',metrics.log_loss(test_y,model[i].predict(test_X_new)))
#   print('Cohen_Kappa_Score: ',cohen_kappa_score(test_y,model[i].predict(test_X_new)))
# 
#   print()
#   print()
#   name = ['Support Vector Machine Model','Random Forest Model','AdaBoost Classifier','Decision Tree Classifier','GradientBoosting Classifier','XGBclassifier', 'Logistic Regression Classifier']
#   col_value = ['blue','purple','red','orange','green','black','purple']
#   model_accuracy = pd.Series(data=[var], index=[name[i]])
#   fig = plt.figure(figsize=(5,5))
#   width = 0.75
#   model_accuracy.sort_values().plot.bar(alpha=0.8, color=[col_value[i]])
#   plt.xticks(rotation=0)
#   plt.title('Model Accuracy')
#   plt.ylabel('Accuracy (%)')
#   plt.show()
#   print()
#   print()

"""##Calculate Voting(10 Columns)"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.ensemble import VotingClassifier
# 
# g =GradientBoostingClassifier( n_estimators=400,max_features=4,random_state=42)
# r = RandomForestClassifier(n_estimators = 4, criterion='entropy', random_state = 20)
# s = SVC(C=10,kernel='poly',gamma=100)
# d = DecisionTreeClassifier()
# x =XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 400)
# evc = VotingClassifier(estimators=[('g',g),('r',r),('s',s),('d',d),('x',x)], voting='hard')
# evc.fit(train_X_new,train_y)
# evc.score(test_X_new,test_y)
# print("Voting Accuracy: ",evc.score(test_X_new,test_y))

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.ensemble import VotingClassifier
# 
# g = GradientBoostingClassifier( n_estimators=400,max_features=2,random_state=42)
# r = RandomForestClassifier(n_estimators = 4, criterion='entropy', random_state = 20)
# s = SVC(C=10,kernel='poly',gamma=100)
# d = DecisionTreeClassifier()
# evc = VotingClassifier(estimators=[('g',g), ('r',r),('s',s),('d',d)], voting='hard')
# evc.fit(train_X_new,train_y)
# evc.score(test_X_new,test_y)
# print("Voting Accuracy: ",evc.score(test_X_new,test_y))

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.ensemble import VotingClassifier
# 
# s = SVC(C=10,kernel='poly',gamma=100)
# x=XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 400)
# d = DecisionTreeClassifier()
# evc = VotingClassifier(estimators=[('s',s),('x',x),('d',d)], voting='hard')
# evc.fit(train_X_new,train_y)
# evc.score(test_X_new,test_y)
# print("Voting Accuracy: ",evc.score(test_X_new,test_y))

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.ensemble import VotingClassifier
# 
# s = SVC(C=10,kernel='poly',gamma=100)
# d = DecisionTreeClassifier()
# g=GradientBoostingClassifier( n_estimators=400,max_features=2,random_state=42)
# evc = VotingClassifier(estimators=[('s',s), ('d',d),('g',g)], voting='hard')
# evc.fit(train_X_new,train_y)
# evc.score(test_X_new,test_y)
# print("Voting Accuracy: ",evc.score(test_X_new,test_y))

"""#AUC Score"""

from sklearn.metrics import roc_curve, roc_auc_score
import sklearn.metrics as metrics

##support Vector Machine Roc curve
svm_model = SVC(probability=True)
svm_model.fit(train_X_new, train_y) 
y_score1 = svm_model.predict_proba(test_X_new)[:,1]
##Plot Receiving Operating Characteristic Curve
##Create true and false positive rate
false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
print('score of support vector machine: ',roc_auc_score(test_y, y_score1))
#plot Roc curves
plt.subplots(1, figsize=(5,5))
plt.title('Support Vector Machine Roc Curve')
plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Support Vector Machine")
plt.plot([0,1], ls="--")
plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()
print()
print() 
##Support Vector  Machine Aus curve
svm = SVC(probability=True)
svm.fit(train_X_new,train_y)
y_pred_proba=svm.predict(test_X_new)
##Auc Curve
plt.subplots(1, figsize=(5,5))
y_pred_proba=svm.predict_proba(test_X_new)[::,1]
fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
auc=metrics.roc_auc_score(test_y,y_pred_proba)
plt.title('Support Vector  Machine Aus curve')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score
import sklearn.metrics as metrics

##Random Forest Classification
from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 20)
rf_model.fit(train_X_new, train_y)
y_score1 = rf_model.predict_proba(test_X_new)[:,1]
##Plot Receiving Operating Characteristic Curve
##Create true and false positive rate
false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
print('score of Random Forest Classification: ',roc_auc_score(test_y, y_score1))
#plot Roc curves
plt.subplots(1, figsize=(5,5))
plt.title('Random Forest Classification Roc Curve')
plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Random Forest Classification")
plt.plot([0,1], ls="--")
plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()
print()
print()
##Random Forest Classification Aus curve
rf_model = RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 20)
rf_model.fit(train_X_new, train_y)
y_pred_proba=rf_model.predict(test_X_new)
##Auc Curve
plt.subplots(1, figsize=(5,5))
y_pred_proba=rf_model.predict_proba(test_X_new)[::,1]
fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
auc=metrics.roc_auc_score(test_y,y_pred_proba)
plt.title('Random Forest Classification Aus curve')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score
import sklearn.metrics as metrics


##Decision Tree classifier 
classifier= DecisionTreeClassifier(criterion='entropy', random_state=0)
classifier.fit(train_X_new, train_y)
y_score1 = classifier.predict_proba(test_X_new)[:,1]
##Plot Receiving Operating Characteristic Curve
##Create true and false positive rate
false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
print('score of Decision Tree classifier  : ',roc_auc_score(test_y, y_score1))
#plot Roc curves
plt.subplots(1, figsize=(5,5))
plt.title('Decision Tree classifier  Roc Curve')
plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Decision Tree classifier")
plt.plot([0,1], ls="--")
plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()
print()
print()


##Decision Tree classifier 
classifier= DecisionTreeClassifier(criterion='entropy', random_state=0)
classifier.fit(train_X_new, train_y)
y_score1 = classifier.predict_proba(test_X_new)[:,1] 


##Auc Curve
plt.subplots(1, figsize=(5,5))
y_pred_proba=rf_model.predict_proba(test_X_new)[::,1]
fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
auc=metrics.roc_auc_score(test_y,y_pred_proba)
plt.title('Decision Tree classifier  Aus curve')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score
import sklearn.metrics as metrics


##GradientBoostingClassifier 5
gb_model=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
gb_model.fit(train_X_new, train_y)
y_score1 = gb_model.predict_proba(test_X_new)[:,1]
##Plot Receiving Operating Characteristic Curve
##Create true and false positive rate
false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
print('Gradient Boosting Classifier: ',roc_auc_score(test_y, y_score1))
#plot Roc curves
plt.subplots(1, figsize=(5,5))
plt.title('Gradient Boosting Classifier')
plt.plot(false_positive_rate1,true_positive_rate1 ,label= "GradientBoosting Classifier")
plt.plot([0,1], ls="--")
plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()
print()
print()
##GradientBoostingClassifier 5
gb_model=GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42)
gb_model.fit(train_X_new, train_y)
y_pred_proba=gb_model.predict(test_X_new)
##Auc Curve
plt.subplots(1, figsize=(5,5))
y_pred_proba=gb_model.predict_proba(test_X)[::,1]
fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
auc=metrics.roc_auc_score(test_y,y_pred_proba)
plt.title('GradientBoosting Classifier')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score
import sklearn.metrics as metrics

##Adaboost classifier      7
ada_model = AdaBoostClassifier(n_estimators = 20, random_state = 42)
ada_model.fit(train_X_new, train_y)
y_score1 = ada_model.predict_proba(test_X_new)[:,1]
##Plot Receiving Operating Characteristic Curve
##Create true and false positive rate
false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
print('Adabost Classifier: ',roc_auc_score(test_y, y_score1))
#plot Roc curves
plt.subplots(1, figsize=(5,5))
plt.title('Adabost Classifier')
plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Adabost Classifier")
plt.plot([0,1], ls="--")
plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()
print()
print()
##Adabost classifier      7
ada_model = AdaBoostClassifier(n_estimators = 20, random_state = 42)
ada_model.fit(train_X_new, train_y)
y_pred_proba=ada_model.predict(test_X_new)
##Auc Curve
plt.subplots(1, figsize=(5,5))
y_pred_proba=ada_model.predict_proba(test_X_new)[::,1]
fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
auc=metrics.roc_auc_score(test_y,y_pred_proba)
plt.title('Adabost Classifier')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score
import sklearn.metrics as metrics


##XGB classifier      7
xgb_model =XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 200)
xgb_model.fit(train_X_new, train_y)
y_score1 = xgb_model.predict_proba(test_X_new)[:,1]
##Plot Receiving Operating Characteristic Curve
##Create true and false positive rate
false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
print('XGB Classifier: ',roc_auc_score(test_y, y_score1))
#plot Roc curves
plt.subplots(1, figsize=(5,5))
plt.title('XGB Classifier')
plt.plot(false_positive_rate1,true_positive_rate1 ,label= "XGB Classifier")
plt.plot([0,1], ls="--")
plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()
print()
print()
##XGB classifier      7
xgb_model =XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200)
xgb_model.fit(train_X_new, train_y)
y_pred_proba=xgb_model.predict(test_X_new)
##Auc Curve
plt.subplots(1, figsize=(5,5))
y_pred_proba=xgb_model.predict_proba(test_X_new)[::,1]
fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
auc=metrics.roc_auc_score(test_y,y_pred_proba)
plt.title('XGB Classifier')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score
import sklearn.metrics as metrics


##Logistic Regression classifier      7
lr_model =LogisticRegression(random_state= 42)
lr_model.fit(train_X_new, train_y)
y_score1 = lr_model.predict_proba(test_X_new)[:,1]
##Plot Receiving Operating Characteristic Curve
##Create true and false positive rate
false_positive_rate1, true_positive_rate1,threshold1 = roc_curve(test_y, y_score1)
print('Logistic Regression Classifier: ',roc_auc_score(test_y, y_score1))
#plot Roc curves
plt.subplots(1, figsize=(5,5))
plt.title('Logistic Regression Classifier')
plt.plot(false_positive_rate1,true_positive_rate1 ,label= "Logistic Regression Classifier")
plt.plot([0,1], ls="--")
plt.plot([0,0],[1,0], c=".7"), plt.plot([1,1],c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()
print()
print()
##XGB classifier      7
lr_model =LogisticRegression(random_state= 42)
lr_model.fit(train_X_new, train_y)
y_pred_proba=xgb_model.predict(test_X_new)
##Auc Curve
plt.subplots(1, figsize=(5,5))
y_pred_proba=lr_model.predict_proba(test_X_new)[::,1]
fpr, tpr, _ =metrics.roc_curve(test_y, y_pred_proba)
auc=metrics.roc_auc_score(test_y,y_pred_proba)
plt.title('Logistic Regression Classifier')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

"""#Recall, Precision, F1 Score

**SVM**
"""

x1= svm_model.predict(test_X_new)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, x1, average='macro')
print("precision: ", pr)
print("Recall: ", rc)
print("F1 Score: ", fs)

"""**Random Forest**"""

x2=rf_model.predict(test_X_new)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, x2, average='macro')
print("precision: ", pr)
print("Recall: ", rc)
print("F1 Score: ", fs)

"""**AdaBoost**"""

x3= ada_model.predict(test_X_new)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, x3, average='macro')
print("precision: ", pr)
print("Recall: ", rc)
print("F1 Score: ", fs)

"""**XGB**"""

x4= xgb_model.predict(test_X_new)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, x4, average='macro')
print("precision: ", pr)
print("Recall: ", rc)
print("F1 Score: ", fs)

"""**Decision Tree**"""

x5= classifier.predict(test_X_new)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, x5, average='macro')
print("precision: ", pr)
print("Recall: ", rc)
print("F1 Score: ", fs)

"""**Logistic Regression**"""

x6= lr_model.predict(test_X_new)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, x6, average='macro')
print("precision: ", pr)
print("Recall: ", rc)
print("F1 Score: ", fs)

"""**Gradient Boosting**"""

x8= gb_model.predict(test_X_new)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, x8, average='macro')
print("precision: ", pr)
print("Recall: ", rc)
print("F1 Score: ", fs)

"""#Recall, Precision, F1 Score Before Feature Selection)

**SVM**
"""

x7= svm_model.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, x7, average='macro')
print("precision: ", pr)
print("Recall: ", rc)
print("F1 Score: ", fs)

"""**Random Forest**"""

x9= rf_model.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, x9, average='macro')
print("precision: ", pr)
print("Recall: ", rc)
print("F1 Score: ", fs)

"""**Decision Tree**"""

x10= classifier.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, x10, average='macro')
print("precision: ", pr)
print("Recall: ", rc)
print("F1 Score: ", fs)

"""**XGB**


"""

x11= xgb_model.predict(test_X_new)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, x11, average='macro')
print("precision: ", pr)
print("Recall: ", rc)
print("F1 Score: ", fs)

"""**Logistic Regression**"""

x12= lr_model.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, x12, average='macro')
print("precision: ", pr)
print("Recall: ", rc)
print("F1 Score: ", fs)

"""**Gradient Boosting**"""

x13= gb_model.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, x13, average='macro')
print("precision: ", pr)
print("Recall: ", rc)
print("F1 Score: ", fs)

"""**AdaBoost**"""

x14= ada_model.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, x14, average='macro')
print("precision: ", pr)
print("Recall: ", rc)
print("F1 Score: ", fs)

"""#CV Score"""



"""#to copy"""

def get_score(model, train_X_new, test_X_new, train_y, test_y):
    model.fit(train_X_new, train_y)
    return model.score(test_X_new, test_y)

get_score(SVC(), train_X_new, test_X_new, train_y, test_y)

get_score(RandomForestClassifier(), train_X_new, test_X_new, train_y, test_y)

get_score(DecisionTreeClassifier(), train_X_new, test_X_new, train_y, test_y)

get_score(GradientBoostingClassifier(n_estimators=300,max_features=2,random_state=42), train_X_new, test_X_new, train_y, test_y)

get_score(XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200),train_X_new, test_X_new, train_y, test_y)

get_score(AdaBoostClassifier(),train_X_new, test_X_new, train_y, test_y)

get_score(LogisticRegression(),train_X_new, test_X_new, train_y, test_y)

"""StratifiedKFold"""

from sklearn.model_selection import StratifiedKFold
folds = StratifiedKFold(n_splits=5)

scores_svm1 = []
scores_rf1= []
scores_decision1= []
scores_gradient1 = []
scores_lr1=[]
scores_ab1=[]




for train_index, test_index in folds.split(digits.data,digits.target):
    train_X_new, test_X_new, train_y, test_y = digits.data[train_index],digits.data[test_index], \
                                      digits.target[train_index], digits.target[test_index]  
    scores_svm1.append(get_score(SVC(C=10,kernel='poly',gamma='auto'),train_X_new, test_X_new, train_y, test_y))
    scores_rf1.append(get_score(RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 14), train_X_new, test_X_new, train_y, test_y))
    scores_decision1.append(get_score(DecisionTreeClassifier(), train_X_new, test_X_new, train_y, test_y))
   ##scores_gradient1.append(get_score(GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42), train_X_new, test_X_new, train_y, test_y))
    ##scores_lr1.append(get_score(LogisticRegression(random_state= 42)), train_X_new, test_X_new, train_y, test_y))
   ## scores_ab1.append(get_score(AdaBoostClassifier(n_estimators = 20, random_state = 42)), train_X_new, test_X_new, train_y, test_y))

scores_svm1

scores_rf1

scores_decision1

scores_gradient1

scores_ab1

scores_lr1

"""cross_val_score function"""

##cross_val_score function
from sklearn.model_selection import cross_val_score

cross_val_score(SVC(C=10,kernel='poly',gamma='auto'), digits.data, digits.target,cv=5)

cross_val_score(RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 14), digits.data, digits.target,cv=5)

cross_val_score(DecisionTreeClassifier(), digits.data, digits.target,cv=5)

cross_val_score(GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42), digits.data, digits.target,cv=5)

cross_val_score(LogisticRegression(random_state= 42), digits.data, digits.target,cv=5)

cross_val_score(AdaBoostClassifier(n_estimators = 20, random_state = 42), digits.data, digits.target,cv=5)

"""##Parameter tunning using k fold cross validation"""

scores8 = cross_val_score(SVC(C=10,kernel='poly',gamma='auto'), digits.data, digits.target,cv=5)
np.average(scores8)

scores9 = cross_val_score(RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 14), digits.data, digits.target,cv=5)
np.average(scores9)

scores10 = cross_val_score(DecisionTreeClassifier(), digits.data, digits.target,cv=5)
np.average(scores10)

scores11 = cross_val_score(GradientBoostingClassifier( n_estimators=300,max_features=2,random_state=42), digits.data, digits.target,cv=5)
np.average(scores11)

scores12 = cross_val_score(XGBClassifier( colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200), digits.data, digits.target,cv=5)
np.average(scores12)

scores13 = cross_val_score(AdaBoostClassifier( n_estimators = 20, random_state = 42), digits.data, digits.target,cv=5)
np.average(scores13)

scores14 = cross_val_score(LogisticRegression(random_state= 42), digits.data, digits.target,cv=5)
np.average(scores14)



"""##Bagging """

# Commented out IPython magic to ensure Python compatibility.
# ## Random Forest
# %%time
# bgr = BaggingClassifier(RandomForestClassifier(n_estimators = 3, criterion='entropy', random_state = 20), max_samples= 0.5, max_features = 7, n_estimators = 30)
# bgr.fit(train_X, train_y)
#

# Commented out IPython magic to ensure Python compatibility.
# %%time
# bgr.score(test_X,test_y)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# bgr.score(train_X,train_y)

# Commented out IPython magic to ensure Python compatibility.
# ## Decision Tree
# %%time
# bgd = BaggingClassifier(RandomForestClassifier(), max_samples= 0.5, max_features = 7, n_estimators = 30)
# bgd.fit(train_X, train_y)
#

# Commented out IPython magic to ensure Python compatibility.
# %%time
# bgd.score(test_X,test_y)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# bgd.score(train_X,train_y)



"""##Boosting (All Columns)"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# ##Gradient Boost
# from sklearn.ensemble import AdaBoostClassifier
# adb1 = AdaBoostClassifier(GradientBoostingClassifier(n_estimators=300,max_features=2,random_state=42),n_estimators = 5, learning_rate = 1)
# adb1.fit(train_X, train_y)

adb1.score(test_X,test_y)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# ##adaboost 
# from sklearn.ensemble import AdaBoostClassifier
# adb2 = AdaBoostClassifier(AdaBoostClassifier(n_estimators = 20, random_state = 42))
# adb2.fit(train_X, train_y)

adb2.score(test_X,test_y)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# ##XGB
# from sklearn.ensemble import AdaBoostClassifier
# adb3 = AdaBoostClassifier(XGBClassifier(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 200))
# adb3.fit(train_X, train_y)

adb3.score(test_X,test_y)



